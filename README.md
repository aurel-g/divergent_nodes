# Divergent Nodes - Custom ComfyUI Nodes

This repository contains custom nodes for ComfyUI.

## Installation

1.  Clone this repository into your `ComfyUI/custom_nodes/` directory:
    ```bash
    cd ComfyUI/custom_nodes/
    git clone https://github.com/thedivergentai/divergent_nodes.git divergent_nodes
    ```
2.  **Set up API Key (for Gemini Node):**
    *   Create a `.env` file in the `divergent_nodes` directory (this directory).
    *   Add your Google AI Studio API key to the `.env` file like this: `GEMINI_API_KEY=YOUR_API_KEY_HERE`
    *   See the `.env.example` file for the format.
    *   The `.env` file is automatically ignored by git via `.gitignore`.
3.  **Compile `llama-gemma3-cli.exe` (for Gemma3 Vision Node):**
    *   This node requires the `llama-gemma3-cli.exe` executable from the `llama.cpp` project.
    *   Follow the instructions at [https://github.com/ggml-org/llama.cpp/discussions/12348](https://github.com/ggml-org/llama.cpp/discussions/12348) to clone and prepare the `llama.cpp` repository.
    *   **For GPU acceleration (Recommended):** Compile `llama-gemma3-cli` with CUDA support enabled. Delete any existing `build` directory inside `llama.cpp`, then run CMake configuration with the CUDA flag:
        ```powershell
        # Inside the llama.cpp directory
        cmake -B build -DLLAMA_CUBLAS=ON
        cmake --build build --target llama-gemma3-cli --config Release
        ```
        (This requires the NVIDIA CUDA Toolkit to be installed correctly.)
    *   **For CPU-only:** Compile without the CUDA flag (this will be much slower):
        ```powershell
        # Inside the llama.cpp directory
        cmake -B build
        cmake --build build --target llama-gemma3-cli --config Release
        ```
    *   Ensure the compiled `llama-gemma3-cli.exe` file exists (likely in `llama.cpp\build\bin\Release`). The node defaults to this path (adjust `DEFAULT_LLAMA_CLI_PATH` in the script or use the `cli_path_override` input if yours is different).
4.  Install/update the required Python dependencies:
    ```bash
    cd divergent_nodes
    pip install -r requirements.txt
    ```
5.  Restart ComfyUI.

The nodes should now be available in their respective categories when you right-click on the ComfyUI canvas.

## Nodes

### CLIP Token Counter

Counts the number of tokens generated by a CLIP tokenizer for the input text.

**Inputs:**

*   `text` (STRING): The text string you want to analyze.
*   `tokenizer_name` (STRING): The name of the Hugging Face CLIP tokenizer model to use (e.g., `openai/clip-vit-base-patch32`, `stabilityai/stable-diffusion-clip-vit-large-patch14`). Defaults to `openai/clip-vit-base-patch32`.

**Outputs:**

*   `token_count` (INT): The total number of tokens generated for the input text by the selected tokenizer.

**Category:** `Divergent Nodes ðŸ‘½/Text`

### Gemini API Node

Connects to the Google Gemini API to generate text based on a prompt and optional image input.

**Inputs:**

*   `model` (COMBO): Select the Gemini model to use. The list is dynamically fetched from the API if your API key is configured, otherwise defaults are shown.
*   `prompt` (STRING): The text prompt for the model.
*   `image_optional` (IMAGE): An optional image input for multimodal prompts.
*   `temperature` (FLOAT): Controls randomness (0.0-1.0). Lower values are more deterministic.
*   `top_p` (FLOAT): Nucleus sampling parameter (0.0-1.0).
*   `top_k` (INT): Top-k sampling parameter.
*   `max_output_tokens` (INT): Maximum number of tokens to generate.
*   `safety_harassment` (COMBO): Block threshold for harassment content (Options: "Default (Unspecified)", "Block Low & Above", "Block Medium & Above", "Block High Only", "Block None").
*   `safety_hate_speech` (COMBO): Block threshold for hate speech content (Options: "Default (Unspecified)", "Block Low & Above", "Block Medium & Above", "Block High Only", "Block None").
*   `safety_sexually_explicit` (COMBO): Block threshold for sexually explicit content (Options: "Default (Unspecified)", "Block Low & Above", "Block Medium & Above", "Block High Only", "Block None").
*   `safety_dangerous_content` (COMBO): Block threshold for dangerous content (Options: "Default (Unspecified)", "Block Low & Above", "Block Medium & Above", "Block High Only", "Block None").

**Outputs:**

*   `text` (STRING): The generated text response from the Gemini API.

**Category:** `Divergent Nodes ðŸ‘½/Gemini`

### Gemma3 Vision Node

Runs the Gemma 3 vision model using the experimental `llama-gemma3-cli` executable from `llama.cpp`. This allows for text generation based on prompts and optional image analysis.

**Prerequisites:**

*   You **must** compile `llama-gemma3-cli.exe` separately, ideally with CUDA support (see step 3 in Installation).
*   The node needs the correct path to this executable (either the default path hardcoded in the script or provided via `cli_path_override`).
*   The required models for the selected size (12B or 27B) will be downloaded automatically via `huggingface-hub` on first run to your Hugging Face cache.

**Inputs:**

*   `model_size` (COMBO): Select the model size ("12B" or "27B"). Defaults to "12B". This determines which models are downloaded and used.
*   `prompt` (STRING): The text prompt for the model.
*   `n_gpu_layers` (INT): Number of model layers to offload to the GPU. Set to 0 for CPU only, or a high number (e.g., 99) to offload as many as possible (requires CUDA-enabled build). Defaults to 99.
*   `image_optional` (IMAGE): An optional image input. If provided, the node saves it as a temporary PNG file and passes the path to the `llama-gemma3-cli` process.
*   `temperature` (FLOAT): Controls randomness (0.0-2.0). Defaults to 0.8.
*   `top_k` (INT): Top-k sampling parameter. Defaults to 40.
*   `top_p` (FLOAT): Nucleus sampling parameter (0.0-1.0). Defaults to 0.95.
*   `cli_path_override` (STRING): Optional. Provide the full path to your `llama-gemma3-cli.exe` if it's not in the default location specified in the script.

**Outputs:**

*   `text` (STRING): The generated text response from the Gemma 3 model via the CLI. Errors during execution will also be returned in this string.

**Category:** `Divergent Nodes ðŸ‘½/Gemma`
